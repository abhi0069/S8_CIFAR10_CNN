{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#!pip install albumentations\n",
        "\n",
        "#import albumentations as A\n",
        "#from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YtssFUKb-jqx"
      },
      "outputs": [],
      "source": [
        "# Calculate CIFAR10 mean and std\n",
        "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "'''\n",
        "# Train Phase transformations\n",
        "train_transforms = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.CoarseDropout(\n",
        "        max_holes=1, max_height=16, max_width=16,\n",
        "        min_holes=1, min_height=16, min_width=16,\n",
        "        fill_value=CIFAR_MEAN, mask_fill_value=None,\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = A.Compose([\n",
        "    A.Normalize(mean=CIFAR_MEAN, std=CIFAR_STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "'''\n",
        "\n",
        "# Replace albumentations transforms with torchvision transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "# Custom dataset wrapper for albumentations\n",
        "class AlbumentationDataset:\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        image = image.numpy().transpose(1, 2, 0)  # Convert to HWC format\n",
        "        \n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "            \n",
        "        return image, label\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4A84rlfDA23"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "train_data = datasets.CIFAR10('./data', train=True, download=True)\n",
        "test_data = datasets.CIFAR10('./data', train=False, download=True)\n",
        "\n",
        "train = AlbumentationDataset(train_data, train_transforms)\n",
        "test = AlbumentationDataset(test_data, test_transforms)\n",
        "'''\n",
        "\n",
        "train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8OLDR79DrHG",
        "outputId": "208ff21d-7318-456b-c3d2-c1bec87ec530"
      },
      "outputs": [],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFjoFekE_va"
      },
      "source": [
        "# Data Statistics\n",
        "\n",
        "It is important to know your data very well. Let's check some of the statistics around our data and how it actually looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "hWZPPo3yEHDW",
        "outputId": "78a196e2-0105-4eb3-b6d0-21ebe71e3b5c"
      },
      "outputs": [],
      "source": [
        "# We'd need to convert it into Numpy! Remember above we have converted it into tensors already\n",
        "'''\n",
        "train_data = train.dataset.data\n",
        "train_data = train.transform(train_data.numpy())\n",
        "\n",
        "print('[Train]')\n",
        "print(' - Numpy Shape:', train.dataset.data.shape)\n",
        "print(' - Tensor Shape:', train.dataset.data.size())\n",
        "print(' - min:', torch.min(train_data))\n",
        "print(' - max:', torch.max(train_data))\n",
        "print(' - mean:', torch.mean(train_data))\n",
        "print(' - std:', torch.std(train_data))\n",
        "print(' - var:', torch.var(train_data))\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l9lNaWYKuik"
      },
      "source": [
        "## MORE\n",
        "\n",
        "It is important that we view as many images as possible. This is required to get some idea on image augmentation later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "hXXAg8hbK16u",
        "outputId": "7423f367-c928-43eb-dd19-1fc39c14dd19"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h"
      },
      "source": [
        "# The model\n",
        "Let's start with the model we first saw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7FXQlB9kH1ov"
      },
      "outputs": [],
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, \n",
        "                                  stride=stride, padding=padding, groups=in_channels)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # C1 Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 3, padding=1, bias=False),  # RF: 3\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(24),\n",
        "            nn.Conv2d(24, 24, 3, padding=1, bias=False),  # RF: 5\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(24)\n",
        "        )\n",
        "        \n",
        "        # C2 Block\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            DepthwiseSeparableConv(24, 36, 3, padding=1),  # RF: 7\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(36),\n",
        "            nn.Conv2d(36, 36, 3, stride=2, padding=1, bias=False),  # RF: 11\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(36)\n",
        "        )\n",
        "        \n",
        "        # C3 Block\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(36, 48, 3, padding=2, dilation=2, bias=False),  # RF: 19\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.Conv2d(48, 48, 3, stride=2, padding=1, bias=False),  # RF: 27\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(48)\n",
        "        )\n",
        "        \n",
        "        # C4 Block - Final block outputs number of classes directly\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(48, 64, 3, padding=1, bias=False),  # RF: 35\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(64, 64, 3, stride=2, padding=1, bias=False),  # RF: 51\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(-1, 64)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is.\n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skB97zIJQQe",
        "outputId": "6179ec22-1282-4694-9200-759137ce748b"
      },
      "outputs": [],
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs.\n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fbkF2nN_LYIb"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, scheduler, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Add scheduler step\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMCFxeAKOB53",
        "outputId": "42657b33-a47e-4281-9e7b-8591670c4481"
      },
      "outputs": [],
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.1,\n",
        "    epochs=30,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.2,\n",
        "    div_factor=10\n",
        ")\n",
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, scheduler, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87RaqGSEOWDe"
      },
      "outputs": [],
      "source": [
        "t = [t_items.item() for t_items in train_losses]\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(t)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[1, 0].plot(train_acc)\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[0, 1].plot(test_losses)\n",
        "axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1, 1].plot(test_acc)\n",
        "axs[1, 1].set_title(\"Test Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odozjbIvY12p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
